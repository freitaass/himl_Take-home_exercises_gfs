{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aluno: Gabriel Freitas Santos\n",
    "MEC 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - Desenvolvimento do Modelo AR do trabalho anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python38\\lib\\site-packages\\statsmodels\\compat\\pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n",
      "C:\\Users\\Gabriel Freitas\\AppData\\Local\\Temp\\ipykernel_23972\\2114589272.py:15: DeprecationWarning: Please use `mode` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ca39fb50284303978f10a900f57c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from os import getcwd,pardir\n",
    "from os.path import join ,abspath\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from statsmodels.tsa import ar_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats.stats import mode\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (train_test_split, RepeatedKFold,\n",
    "RandomizedSearchCV)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "fname = join(abspath(join(getcwd(), pardir))+'\\\\02_feature','data3SS2009.mat')\n",
    "mat_contents = sio.loadmat(fname)\n",
    "dataset = mat_contents['dataset']\n",
    "N, Chno, Nc = dataset.shape\n",
    "y = mat_contents['labels'].reshape(Nc)\n",
    "Ch1 = dataset[:,0,:] # célula de carga: força do shaker\n",
    "Ch2 = dataset[:,1,:] # acelerômetro: base\n",
    "Ch3 = dataset[:,2,:] # acelerômetro: 1o andar\n",
    "Ch4 = dataset[:,3,:] # acelerômetro: 2o andar\n",
    "Ch5 = dataset[:,4,:] # acelerômetro: 3o andar\n",
    "FeatAR = []\n",
    "na=30 #Model Order\n",
    "for i in tqdm(range(Nc)):\n",
    "    ARmodel2 = ar_model.AutoReg(Ch2[:,i],na).fit()\n",
    "    ARmodel3 = ar_model.AutoReg(Ch3[:,i],na).fit()\n",
    "    ARmodel4 = ar_model.AutoReg(Ch4[:,i],na).fit()\n",
    "    ARmodel5 = ar_model.AutoReg(Ch5[:,i],na).fit()\n",
    "    ARparams = np.concatenate([ARmodel2.params,ARmodel3.params,ARmodel4.params,ARmodel5.params])\n",
    "    FeatAR.append(ARparams)\n",
    "FeatAR=np.array(FeatAR)\n",
    "FeatAR.shape # X1\n",
    "ln,cols = FeatAR.shape\n",
    "#Montar metodo de normalização\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "dfAR = pd.concat([pd.DataFrame(scaler.fit_transform(FeatAR)),pd.DataFrame({'target':y})],axis=1) #Normalização e criação de DF para plot de X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01 - Design of Hyperparameter search:\n",
    "\n",
    "Testing 3 different models: softamax, SVM and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(multi_class='multinomial'), SVC(), KNeighborsClassifier()]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = []\n",
    "models.append(LogisticRegression(multi_class='multinomial'))\n",
    "models.append(SVC())\n",
    "models.append(KNeighborsClassifier())\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters to be tested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids =[]\n",
    "param_grids.append( #Softmax\n",
    "    \n",
    "        {\n",
    "            \"C\":[1, 10, 20, 60, 70, 100],\n",
    "            \"solver\" :[ 'lbfgs', 'liblinear', 'sag']  \n",
    "        }\n",
    "    \n",
    ")\n",
    "param_grids.append( #SVC\n",
    "    \n",
    "        {\n",
    "            \"C\"      : stats.loguniform(1e-1,1e3),\n",
    "            \"kernel\" : ['linerar','poly','rbf','sigmoid'],\n",
    "            \"degree\" : stats.randint(2,5),\n",
    "            \"gamma\"  : stats.loguniform(1e-4,1e0),\n",
    "            \"epsilon\"  : stats.loguniform(1e-4,1e1)\n",
    "        }\n",
    "    \n",
    ")\n",
    "param_grids.append( #KNN\n",
    "    \n",
    "        {\n",
    "            \"n_neighbors\" : stats.randint(2,100),\n",
    "            \"kernel\"      : [\"uniform\",\"distance\"]            \n",
    "        }\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get results for default parameters from each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996d564d24fb494cb244926de3a4c0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteração 1 - LogisticRegression(multi_class='multinomial')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 18 is smaller than n_iter=100. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "1500 fits failed out of a total of 4500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1519, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 483, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Program Files\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: Acurácia=0.9970588235294118\n",
      "\n",
      "Iteração 2 - SVC()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfolds = 5\n",
    "nkiter = 50\n",
    "n_iter = 100\n",
    "acc=[]\n",
    "cfmx =[]\n",
    "best_params =[]\n",
    "for i,md in enumerate(tqdm(models)):\n",
    "    print(f'Iteração {i+1} - {md}\\n')\n",
    "    #Separar Data set em conjuntos de treino e teste ()\n",
    "    train_x, test_x, train_y, test_y = train_test_split(dfAR[dfAR.columns[0:-1]], dfAR.target, test_size=0.4, random_state=i)\n",
    "\n",
    "    rkf = RepeatedKFold(n_splits=kfolds,n_repeats=nkiter,random_state=i)\n",
    "\n",
    "    #clf = Pipeline([md])\n",
    "\n",
    "    param_grid = param_grids[i]\n",
    "\n",
    "    #Cria modelo\n",
    "    rnd_model = RandomizedSearchCV(md,verbose=0,n_iter=n_iter,n_jobs=4,cv=rkf,\n",
    "                                    random_state=i,param_distributions=param_grid,scoring=accuracy_score)\n",
    "    rnd_model.fit(train_x,train_y)\n",
    "    best_params.append(rnd_model.best_params_)\n",
    "    yh_teste = rnd_model.predict(test_x)\n",
    "    acc.append(accuracy_score(test_y, yh_teste,normalize=True))\n",
    "    cfmx.append(confusion_matrix(test_y, yh_teste))\n",
    "    print(f'Resultados: Acurácia={acc[i]}\\n')\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
