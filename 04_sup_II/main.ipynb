{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aluno: Gabriel Freitas Santos\n",
    "MEC 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - Desenvolvimento do Modelo AR do trabalho anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python38\\lib\\site-packages\\statsmodels\\compat\\pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n",
      "C:\\Users\\Gabriel Freitas\\AppData\\Local\\Temp\\ipykernel_10520\\2114589272.py:15: DeprecationWarning: Please use `mode` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93aece683cec45c2b50684c2c6dbb17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from os import getcwd,pardir\n",
    "from os.path import join ,abspath\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from statsmodels.tsa import ar_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats.stats import mode\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (train_test_split, RepeatedKFold,\n",
    "RandomizedSearchCV)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "fname = join(abspath(join(getcwd(), pardir))+'\\\\02_feature','data3SS2009.mat')\n",
    "mat_contents = sio.loadmat(fname)\n",
    "dataset = mat_contents['dataset']\n",
    "N, Chno, Nc = dataset.shape\n",
    "y = mat_contents['labels'].reshape(Nc)\n",
    "Ch1 = dataset[:,0,:] # célula de carga: força do shaker\n",
    "Ch2 = dataset[:,1,:] # acelerômetro: base\n",
    "Ch3 = dataset[:,2,:] # acelerômetro: 1o andar\n",
    "Ch4 = dataset[:,3,:] # acelerômetro: 2o andar\n",
    "Ch5 = dataset[:,4,:] # acelerômetro: 3o andar\n",
    "FeatAR = []\n",
    "na=30 #Model Order\n",
    "for i in tqdm(range(Nc)):\n",
    "    ARmodel2 = ar_model.AutoReg(Ch2[:,i],na).fit()\n",
    "    ARmodel3 = ar_model.AutoReg(Ch3[:,i],na).fit()\n",
    "    ARmodel4 = ar_model.AutoReg(Ch4[:,i],na).fit()\n",
    "    ARmodel5 = ar_model.AutoReg(Ch5[:,i],na).fit()\n",
    "    ARparams = np.concatenate([ARmodel2.params,ARmodel3.params,ARmodel4.params,ARmodel5.params])\n",
    "    FeatAR.append(ARparams)\n",
    "FeatAR=np.array(FeatAR)\n",
    "FeatAR.shape # X1\n",
    "ln,cols = FeatAR.shape\n",
    "#Montar metodo de normalização\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "dfAR = pd.concat([pd.DataFrame(scaler.fit_transform(FeatAR)),pd.DataFrame({'target':y})],axis=1) #Normalização e criação de DF para plot de X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01 - Design of Hyperparameter search:\n",
    "\n",
    "Testing 3 different models: softamax, SVM and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LRG',LogisticRegression(multi_class='multinomial')))\n",
    "models.append(('SVM',SVC()))\n",
    "models.append(('KNN',KNeighborsClassifier()))\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters to be tested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids =[]\n",
    "param_grids.append( # Softmax\n",
    "    [\n",
    "        {\n",
    "            \"LRG__C\":[1, 10, 20, 30, 40, 50, 60, 70, 100],\n",
    "            \"LRG__solver\" :['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']  \n",
    "        }\n",
    "    ]\n",
    ")\n",
    "param_grids.append( #SVC\n",
    "    [\n",
    "        {\n",
    "            \"C\"      : stats.loguniform(1e-1,1e3),\n",
    "            \"kernel\" : ['linerar','poly','rbf','sigmoid'],\n",
    "            \"degree\" : stats.randint(2,5),\n",
    "            \"gamma\"  : stats.loguniform(1e-4,1e0),\n",
    "            \"epsilon\"  : stats.loguniform(1e-4,1e1)\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "param_grids.append( #KNN\n",
    "    [\n",
    "        {\n",
    "            \"n_neighbors\" : stats.randint(2,100),\n",
    "            \"kernel\"      : [\"uniform\",\"distance\"]            \n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get results for default parameters from each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = 5\n",
    "nkiter = 50\n",
    "n_iter = 100\n",
    "acc=[]\n",
    "cfmx =[]\n",
    "best_params =[]\n",
    "for i,md in enumerate(models):\n",
    "    #Separar Data set em conjuntos de treino e teste ()\n",
    "    train_x, test__x, train_y, test_y = train_test_split(dfAR[dfAR.columns[0:-1]], dfAR.target, test_size=0.4, random_state=i)\n",
    "\n",
    "    rkf = RepeatedKFold(n_splits=kfolds,n_repeats=nkiter,random_state=i)\n",
    "\n",
    "    param_grid = param_grids[i]\n",
    "\n",
    "    #Cria modelo\n",
    "    clf = RandomizedSearchCV(md,verbose=0,scoring=\"accuracy\",n_iter=nkiter,n_jobs=-1,cv=rkf,random_state=i,param_distributions=param_grid)\n",
    "    clf.fit(train_x,train_y)\n",
    "    best_params[i] = clf.best_params()\n",
    "    yh_teste_bch = clf.predict(test_y)\n",
    "    acc[i] = accuracy_score(test_y, yh_teste_bch,normalize=True)\n",
    "    cfmx[i] = confusion_matrix(test_y, yh_teste_bch)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
